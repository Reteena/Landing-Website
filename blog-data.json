{
  "posts": [
    {
      "id": "remembrance-ai-therapy",
      "title": "Remembrance",
      "description": "AI therapeutic service providing reminiscence therapy through interconnected memory knowledge graphs.",
      "category": "product",
      "date": "Feb 5, 2026",
      "author": "",
      "toc": [],
      "content": []
    },
    {
      "id": "low-field-mri",
      "title": "Low field MRI framework",
      "description": "Published framework for low field MRI imaging applications.",
      "category": "research",
      "date": "Jan 28, 2026",
      "author": "",
      "toc": [],
      "content": []
    },
    {
      "id": "cortinet-framework",
      "title": "CortiNet",
      "description": "Framework for reproducible cortical microcircuit modeling with spiking neural networks.",
      "category": "research",
      "date": "Jan 27, 2026",
      "author": "",
      "toc": [
        { "id": "introduction", "title": "Introduction to cortical modeling" },
        { "id": "validation", "title": "Validation against experimental data" },
        { "id": "neuron-models", "title": "Neuron and synapse models" },
        { "id": "results", "title": "Experimental results" }
      ],
      "content": [
        {
          "type": "paragraph",
          "text": "CortiNet provides an open-source framework to design, validate, and analyze models of cortical microcircuits against experimental data from the Allen Brain Observatory."
        },
        {
          "type": "heading",
          "id": "introduction",
          "text": "Introduction to cortical modeling"
        },
        {
          "type": "paragraph",
          "text": "The framework implements standard neurons like Adaptive Exponential Integrate-and-Fire (AdEx) and Leaky Integrate-and-Fire (LIF) models with programmatic access to in-vivo electrophysiology datasets."
        },
        {
          "type": "heading",
          "id": "validation",
          "text": "Validation against experimental data"
        },
        {
          "type": "paragraph",
          "text": "Using data from mouse visual cortex recordings (Session ID 715093703), the framework validates spiking neural networks against firing rates, inter-spike intervals, and local field potential power spectra."
        },
        {
          "type": "heading",
          "id": "neuron-models",
          "text": "Neuron and synapse models"
        },
        {
          "type": "paragraph",
          "text": "The framework includes demonstrations of synaptic plasticity via STDP, neuromodulation effects from dopamine and acetylcholine, and cognitive task performance using working memory paradigms."
        },
        {
          "type": "heading",
          "id": "results",
          "text": "Experimental results"
        },
        {
          "type": "paragraph",
          "text": "A pilot experiment with 120 excitatory and 30 inhibitory neurons reproduced key statistical properties of cortical circuits including irregular spiking patterns and network-level oscillations in the gamma band."
        }
      ]
    },
    {
      "id": "lark-multi-stakeholder",
      "title": "Lark",
      "description": "Biologically inspired neuroevolution framework for multi-stakeholder LLM agent systems.",
      "category": "research",
      "date": "Jan 15, 2026",
      "author": "",
      "toc": [
        { "id": "approach", "title": "Four biological mechanisms" },
        { "id": "evaluation", "title": "Evaluation results" },
        { "id": "comparison", "title": "Model comparisons" },
        { "id": "insights", "title": "Key findings" }
      ],
      "content": [
        {
          "type": "paragraph",
          "text": "Lark couples LLM-driven reasoning with evolutionary search to address verbosity, stakeholder trade-offs, and compute constraints in multi-agent systems."
        },
        {
          "type": "heading",
          "id": "approach",
          "text": "Four biological mechanisms"
        },
        {
          "type": "paragraph",
          "text": "The system integrates plasticity for context-sensitive refinements, duplication and maturation for modular specialization, ranked-choice voting using Borda scoring, and token-based penalties rewarding brevity."
        },
        {
          "type": "heading",
          "id": "evaluation",
          "text": "Evaluation results"
        },
        {
          "type": "paragraph",
          "text": "Across 30 rounds comparing 14 systems, Lark achieved mean rank 2.55 and composite score 29.4 out of 50, finishing top-3 in 80% of rounds while maintaining cost competitiveness at $0.016 per task."
        },
        {
          "type": "heading",
          "id": "comparison",
          "text": "Model comparisons"
        },
        {
          "type": "paragraph",
          "text": "Ablation studies showed all four mechanisms contribute significantly. Removing duplication and maturation created the largest deficit with delta score of 3.5, followed by plasticity at 3.4, ranked-choice voting at 2.4, and token penalties at 2.2."
        },
        {
          "type": "heading",
          "id": "insights",
          "text": "Key findings"
        },
        {
          "type": "paragraph",
          "text": "The framework operates as a discrete-generation evolutionary system rather than a Markov decision process, making it suitable for multi-stakeholder strategy generation where evaluation is holistic rather than sequential."
        }
      ]
    },
    {
      "id": "geneattentionnet",
      "title": "GeneAttentionNet",
      "description": "Attention-based architecture for interpretable gene expression classification on Alzheimer's disease.",
      "category": "research",
      "date": "Jan 14, 2026",
      "author": "",
      "toc": [
        { "id": "architecture", "title": "Model architecture" },
        { "id": "biological-priors", "title": "Biological priors" },
        { "id": "performance", "title": "Performance results" },
        { "id": "insights", "title": "Key insights" }
      ],
      "content": [
        {
          "type": "paragraph",
          "text": "GeneAttentionNet leverages attention mechanisms to learn contextual relationships between genes for Alzheimer's classification from high-dimensional gene expression data."
        },
        {
          "type": "heading",
          "id": "architecture",
          "text": "Model architecture"
        },
        {
          "type": "paragraph",
          "text": "The model projects gene expression vectors into low-dimensional embedding space, structures them through tokenization, and processes via custom multi-head self-attention mechanisms."
        },
        {
          "type": "heading",
          "id": "biological-priors",
          "text": "Biological priors"
        },
        {
          "type": "paragraph",
          "text": "Integration includes a Dynamic Pathway Gate for sample-specific pathway weights, PPI-Masked Attention restricting attention to known protein interactions, and optional Braak-Aware attention for stage-specific gene expression patterns."
        },
        {
          "type": "heading",
          "id": "performance",
          "text": "Performance results"
        },
        {
          "type": "paragraph",
          "text": "On binary Alzheimer's classification using 1247 samples, the model achieved 98.47% training accuracy, demonstrating an 8% improvement over standard multilayer perceptrons and 38% boost over Random Forest."
        },
        {
          "type": "heading",
          "id": "insights",
          "text": "Key insights"
        },
        {
          "type": "paragraph",
          "text": "Multi-head attention on tokenized gene embeddings captured complex nonlinear dependencies between distant genes, bridging the gap between machine learning predictions and biological interpretability in transcriptomic analysis."
        }
      ]
    }
  ]
}
